//
//  STTEngine.swift
//  Openock
//
//  Created by JiJooMaeng on 10/26/25.
//

/*
 STTEngine
 
 Abstract:
 Integration class that combines AudioCaptureManager, AudioIOManager, and STTTranscriberManager
 to provide complete system-wide audio capture and speech-to-text functionality.
 */

import Foundation
import AVFoundation
import CoreAudio
import Combine

@available(macOS 15.0, *)
class STTEngine: NSObject, ObservableObject {
  
  // MARK: - Published Properties (UI State)

  @Published var transcript = ""
  @Published var isRecording = false
  @Published var isPaused = false
  @Published var errorMessage: String?
  @Published var audioLevel: Float = 0.0
  @Published var isReceivingAudio = false
  @Published var isWhistleDetected = false  // íœ˜ìŠ¬ ê°ì§€ ìƒíƒœ
  @Published var whistleProbability: Float = 0.0  // íœ˜ìŠ¬ í™•ë¥  (ë””ë²„ê¹…ìš©)
  @Published var audioEnergy: Float = 0.0  // ì˜¤ë””ì˜¤ ì—ë„ˆì§€ (ë””ë²„ê¹…ìš©)
  @Published var dominantFrequency: Float = 0.0  // ì£¼ìš” ì£¼íŒŒìˆ˜ (ë””ë²„ê¹…ìš©)
  @Published var stage1Probability: Float = 0.0  // 1ë‹¨ê³„ í™•ë¥  (ë””ë²„ê¹…ìš©)
  @Published var stage2Probability: Float = 0.0  // 2ë‹¨ê³„ í™•ë¥  (ë””ë²„ê¹…ìš©)

  // MARK: - Manager Components

  private let captureManager = AudioCaptureManager()
  private let ioManager = AudioIOManager()
  private let transcriberManager = STTTranscriberManager()
  private let whistleDetector = WhistleDetector()  // íœ˜ìŠ¬ ê°ì§€ê¸°
  
  private var deviceID: AudioObjectID = kAudioObjectUnknown
  private var cancellables = Set<AnyCancellable>()
  private var bufferCallCount = 0

  // MARK: - í…ìŠ¤íŠ¸ ìë™ ì •ë¦¬ (5ë¶„ ë¶„ëŸ‰ ìœ ì§€)
  private let maxTextLength: Int = 1500  // ì•½ 5ë¶„ ë¶„ëŸ‰ì˜ í…ìŠ¤íŠ¸

  // MARK: - Initialization
  
  override init() {
    super.init()
    print("ğŸ™ï¸ [STTEngine] Initialized")
    // Observe transcript changes from TranscriberManager
    observeTranscriber()
  }
  
  // MARK: - Public Interface
  
  /// Setup full system audio capture (captures ALL processes)
  func setupSystemCapture(completion: @escaping (Bool) -> Void) {
    print("ğŸ”§ [STTEngine] Setting up full system capture...")
    
    captureManager.setupFullSystemCapture { [weak self] deviceID in
      guard let self = self, let deviceID = deviceID else {
        DispatchQueue.main.async {
          self?.errorMessage = "ì˜¤ë””ì˜¤ ìº¡ì²˜ ì„¤ì • ì‹¤íŒ¨"
          completion(false)
        }
        return
      }
      
      self.deviceID = deviceID
      print("âœ… [STTEngine] Full system capture ready! Device ID: \(deviceID)")
      
      DispatchQueue.main.async {
        completion(true)
      }
    }
  }
  
  /// Start recording and transcription
  func startRecording() {
    print("ğŸ¤ [STTEngine] Starting recording...")
    
    guard deviceID != kAudioObjectUnknown else {
      errorMessage = "ë””ë°”ì´ìŠ¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. setupSystemCapture()ë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”."
      print("âŒ [STTEngine] No device set - call setupSystemCapture() first")
      return
    }
    
    // Start transcription task first
    Task {
      await transcriberManager.startTranscription()
    }
    
    // Give transcription task time to set up
    Task {
      try? await Task.sleep(nanoseconds: 100_000_000) // 0.1 seconds
      
      // Start audio IO
      let success = self.ioManager.startIO(
        deviceID: self.deviceID,
        bufferCallback: { [weak self] buffer in
          self?.handleAudioBuffer(buffer)
        },
        levelCallback: { [weak self] level in
          self?.handleAudioLevel(level)
        }
      )
      
      if success {
        print("âœ… [STTEngine] Recording started successfully")
        DispatchQueue.main.async {
          self.isRecording = true
          self.transcript = ""
          self.errorMessage = nil
        }
      } else {
        self.errorMessage = "ì˜¤ë””ì˜¤ IOë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
        print("âŒ [STTEngine] Failed to start audio IO")
      }
    }
  }
  
  /// Pause recording (audio still captured but not transcribed)
  func pauseRecording() {
    print("â¸ [STTEngine] Pausing recording...")
    ioManager.isPaused = true
    DispatchQueue.main.async {
      self.isPaused = true
    }
  }
  
  /// Resume recording
  func resumeRecording() {
    print("â–¶ï¸ [STTEngine] Resuming recording...")
    ioManager.isPaused = false
    DispatchQueue.main.async {
      self.isPaused = false
    }
  }
  
  /// Stop recording and transcription
  func stopRecording() {
    print("ğŸ›‘ [STTEngine] Stopping recording...")
    
    ioManager.stopIO()
    transcriberManager.stopTranscription()
    
    DispatchQueue.main.async {
      self.isRecording = false
      self.isPaused = false
    }
    
    print("âœ… [STTEngine] Recording stopped")
  }
  
  /// Clear transcript text
  func clearTranscript() {
    transcriberManager.clearTranscript()
    DispatchQueue.main.async {
      self.transcript = ""
      self.errorMessage = nil
    }
  }

  // === âœ… ì¶”ê°€: íŒŒì´í”„ë¼ì¸ ì—°ë™ìš© ê²½ëŸ‰ API =============================

  /// íŒŒì´í”„ë¼ì¸ì´ IOë¥¼ ë‹´ë‹¹í•  ë•Œ, ì „ì‚¬ íŒŒì´í”„ë¼ì¸ë§Œ ì‹œì‘
  @MainActor
  func startTranscriptionOnly() async {
    print("ğŸ™ï¸ [STTEngine] Starting transcription only...")
    await transcriberManager.startTranscription()
    print("âœ… [STTEngine] Transcription started, transcriberManager.isTranscribing: \(transcriberManager.isTranscribing)")
  }

  /// íŒŒì´í”„ë¼ì¸ì´ IOë¥¼ ë‹´ë‹¹í•  ë•Œ, ì „ì‚¬ íŒŒì´í”„ë¼ì¸ë§Œ ì¤‘ì§€
  func stopTranscriptionOnly() {
    print("ğŸ›‘ [STTEngine] Stopping transcription only...")
    transcriberManager.stopTranscription()
    print("âœ… [STTEngine] Transcription stopped, isTranscribing: \(transcriberManager.isTranscribing)")
  }

  /// íŒŒì´í”„ë¼ì¸ì—ì„œ ë°›ì€ PCMì„ ê·¸ëŒ€ë¡œ STTë¡œ ì „ë‹¬
  func feed(buffer: AVAudioPCMBuffer) {
    transcriberManager.processAudio(buffer: buffer)
  }

  // ===================================================================
  
  // MARK: - Private Methods
  
  /// Handle audio buffer from AudioIOManager
  private func handleAudioBuffer(_ buffer: AVAudioPCMBuffer) {
    // Send buffer to transcriber
    transcriberManager.processAudio(buffer: buffer)

    // Update receiving audio status and check whistle (occasionally)
    bufferCallCount += 1

    // Whistle detection (10ë²ˆì— í•œ ë²ˆì”© ì²´í¬ - ë§¤ìš° ë¹ ë¥¸ ë°˜ì‘)
    if bufferCallCount % 10 == 0 {
      // ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰í•˜ì—¬ ë©”ì¸ ì˜¤ë””ì˜¤ ì²˜ë¦¬ì— ì˜í–¥ ì—†ë„ë¡
      DispatchQueue.global(qos: .userInitiated).async { [weak self] in
        guard let self = self else { return }
        let whistleDetected = self.whistleDetector.detectWhistle(from: buffer)

        // UIì— ë””ë²„ê¹… ì •ë³´ ì—…ë°ì´íŠ¸
        DispatchQueue.main.async {
          self.whistleProbability = self.whistleDetector.lastWhistleProbability
          self.audioEnergy = self.whistleDetector.lastRMSEnergy
          self.dominantFrequency = self.whistleDetector.lastDominantFrequency
          self.stage1Probability = self.whistleDetector.lastStage1Probability
          self.stage2Probability = self.whistleDetector.lastStage2Probability
        }

        if whistleDetected {
          DispatchQueue.main.async {
            self.isWhistleDetected = true
            print("ğŸµ [STTEngine] Whistle detected!")
          }

          // 3ì´ˆ í›„ ìë™ìœ¼ë¡œ ì•„ì´ì½˜ ì‚¬ë¼ì§€ê²Œ
          DispatchQueue.main.asyncAfter(deadline: .now() + 3.0) {
            self.isWhistleDetected = false
          }
        }
      }
    }

    if bufferCallCount % 30 == 1 {
      DispatchQueue.main.async {
        self.isReceivingAudio = true
      }
    }
  }
  
  /// Handle audio level updates from AudioIOManager
  private func handleAudioLevel(_ level: Float) {
    DispatchQueue.main.async {
      self.audioLevel = level
    }
  }
  
  // MARK: - Observation
  private func observeTranscriber() {
    // Observe transcript changes
    transcriberManager.$transcript
      .sink { [weak self] newTranscript in
        guard let self = self else { return }
        DispatchQueue.main.async {
          self.transcript = self.formatTranscript(newTranscript)
          self.cleanupOldTextIfNeeded()
        }
      }
      .store(in: &cancellables)

    // Observe error messages
    transcriberManager.$errorMessage
      .sink { [weak self] newError in
        DispatchQueue.main.async {
          self?.errorMessage = newError
        }
      }
      .store(in: &cancellables)
  }
  
  // MARK: - Cleanup
  
  deinit {
    print("ğŸ—‘ï¸ [STTEngine] Deallocating...")
    stopRecording()
  }
  
  // MARK: - STT Post-processing
  private func formatTranscript(_ text: String) -> String {
    guard !text.isEmpty else { return "" }

    // ë¬¸ì¥ë¶€í˜¸(., ?, !, ~, â€¦) ë’¤ì—ì„œ ì¤„ë°”ê¿ˆ
//    let formatted = text.replacingOccurrences(
//      of: "([.!?~â€¦])\\s*",
//      with: "$1\n",
//      options: .regularExpression
//    )
//    return formatted.trimmingCharacters(in: .whitespacesAndNewlines)

    return text.trimmingCharacters(in: .whitespacesAndNewlines)
  }

  // MARK: - í…ìŠ¤íŠ¸ ìë™ ì •ë¦¬
  private func cleanupOldTextIfNeeded() {
    // í…ìŠ¤íŠ¸ê°€ maxTextLengthë¥¼ ì´ˆê³¼í•˜ë©´ ì•ë¶€ë¶„ ì‚­ì œ
    guard transcript.count > maxTextLength else { return }

    // ì´ˆê³¼ëœ ê¸¸ì´ + ì—¬ìœ ë¶„(200ì) ê³„ì‚°
    let excessLength = transcript.count - maxTextLength + 200
    let startIndex = transcript.startIndex

    // ì‚­ì œí•  ê¸°ë³¸ ìœ„ì¹˜
    guard excessLength < transcript.count else {
      transcript = String(transcript.suffix(maxTextLength))
      return
    }

    var cutIndex = transcript.index(startIndex, offsetBy: excessLength, limitedBy: transcript.endIndex) ?? transcript.endIndex

    // ë¬¸ì¥ ë¶€í˜¸(. ! ? ë˜ëŠ” ê³µë°±) ë’¤ì—ì„œ ìë¥´ê¸°
    let sentenceEnders: Set<Character> = [".", "!", "?", " "]
    while cutIndex < transcript.endIndex {
      if sentenceEnders.contains(transcript[cutIndex]) {
        cutIndex = transcript.index(after: cutIndex)
        break
      }
      cutIndex = transcript.index(after: cutIndex)
    }

    // í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
    transcript = String(transcript[cutIndex...])
  }
}
