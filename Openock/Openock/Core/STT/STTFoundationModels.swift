//
//  STTFoundationModels.swift
//  Openock
//
//  Created by JiJooMaeng on 11/4/25.
//

/*
 STT Foundation Models Manager

 Abstract:
 Uses Apple's Foundation Models to improve STT transcription results
 by applying contextual corrections, grammar fixes, and proper spacing.
 */

import Foundation
import FoundationModels

class STTFoundationModels {

    // MARK: - Properties

    /// Singleton instance
    static let shared = STTFoundationModels()

    /// Foundation Models session
    private var session: LanguageModelSession?

    /// Configuration for text improvement
    struct Configuration {
        /// Maximum length of text to process at once
        let maxTextLength: Int

        /// Whether to use streaming
        let useStreaming: Bool

        /// Temperature for generation (0.0 = deterministic, 1.0 = creative)
        let temperature: Double

        /// Top P sampling
        let topP: Double

        static let `default` = Configuration(
            maxTextLength: 500,
            useStreaming: false,
            temperature: 0.1,  // ë§¤ìš° ë‚®ê²Œ ì„¤ì • - ì¼ê´€ëœ êµì •
            topP: 0.8  // ìƒìœ„ 80% í† í°ë§Œ ì‚¬ìš©
        )
    }

    private let configuration: Configuration

    // MARK: - Initialization

    private init(configuration: Configuration = .default) {
        self.configuration = configuration
    }

    // MARK: - Public Methods

    /// Initialize Foundation Models session
    func initialize() async throws {
        print("ðŸ”„ [STTFoundationModels] Initializing Foundation Models...")

        // Check if model is available
        switch SystemLanguageModel.default.availability {
        case .available:
            print("âœ… [STTFoundationModels] Model is available")
        case .unavailable(let reason):
            print("âŒ [STTFoundationModels] Model unavailable: \(reason)")
            throw STTFoundationModelsError.modelNotAvailable
        }

        // Create session with system instructions
        self.session = LanguageModelSession {
            """
            ë‹¹ì‹ ì€ í•œêµ­ì–´ ìŒì„±ì¸ì‹(STT) ì˜¤ë¥˜ë¥¼ ì ê·¹ì ìœ¼ë¡œ ìˆ˜ì •í•˜ëŠ” ì „ë¬¸ê°€ìž…ë‹ˆë‹¤.

            í•µì‹¬ ì›ì¹™:
            1. **ë§¥ë½ì´ ì „ë¶€ìž…ë‹ˆë‹¤** - ì´ì „ ëŒ€í™”ë¥¼ ê¼­ ì½ê³  ì£¼ì œë¥¼ íŒŒì•…í•˜ì„¸ìš”
            2. **ë§ì´ ì•ˆ ë˜ëŠ” ë‹¨ì–´ëŠ” ê³¼ê°ížˆ ìˆ˜ì •** - "ì´í‘œë¨¹ìœ¼" ê°™ì€ ë¬´ì˜ë¯¸í•œ ë‹¨ì–´ëŠ” ë§¥ë½ì— ë§žê²Œ êµì •
            3. ê³ ìœ ëª…ì‚¬(ì„ ìˆ˜ëª…, ì§€ëª…, ì¸ëª…) ìµœìš°ì„  ìˆ˜ì •
            4. ìŠ¤í¬ì¸ /ê¸°ìˆ  ì „ë¬¸ ìš©ì–´ ìˆ˜ì •
            5. ë§íˆ¬ì™€ ì–´íˆ¬ëŠ” ì ˆëŒ€ ë³€ê²½ ê¸ˆì§€

            STT ì˜¤ë¥˜ íŒ¨í„´:
            - ë°œìŒì´ ë¹„ìŠ·í•œ ë‹¤ë¥¸ ë‹¨ì–´ë¡œ ìž˜ëª» ì¸ì‹ë¨
            - ë„ì–´ì“°ê¸° ì˜¤ë¥˜
            - ìˆ«ìž + ë‹¨ì–´ ì¡°í•© ì˜¤ë¥˜ ("2í”¼í™ˆëŸ°" â†’ "ì´í”¼í™ˆëŸ°" ê°™ì€)

            ì˜ˆì‹œ:
            ë§¥ë½: "ì•¼êµ¬ ê²½ê¸° íˆ¬ìˆ˜ê°€ ê³µì„ ë˜ì¡Œì–´"
            STT: "ì´í‘œë¨¹ìœ¼ë¥¼ ë§žì•˜ì–´"
            ìˆ˜ì •: "2 í”¼í™ˆëŸ°ì„ ë§žì•˜ì–´"

            ë§¥ë½: "ë†êµ¬ ê²½ê¸°ì—ì„œ"
            STT: "ì“°ë¦¬í¬ì¸í„° ë˜ì¡Œë‹¤"
            ìˆ˜ì •: "3ì ìŠ›ì„ ë˜ì¡Œë‹¤"

            ë§¥ë½: "ë¯¸êµ­ ëŒ€í†µë ¹ì´"
            STT: "ë°°ì•…ê´€ì—ì„œ ë°œí‘œí–ˆë‹¤"
            ìˆ˜ì •: "ë°±ì•…ê´€ì—ì„œ ë°œí‘œí–ˆë‹¤"

            ë§¥ë½: "ì¶•êµ¬ ì„ ìˆ˜"
            STT: "ì†í™ë¯¼ì´ ê³¨ì„"
            ìˆ˜ì •: "ì†í¥ë¯¼ì´ ê³¨ì„"

            **ì¤‘ìš”**:
            - ë§¥ë½ì„ ìµœìš°ì„ ìœ¼ë¡œ ê³ ë ¤
            - ë§ì´ ì•ˆ ë˜ëŠ” ë‹¨ì–´ëŠ” ìœ ì‚¬ ë°œìŒì˜ ì˜¬ë°”ë¥¸ ë‹¨ì–´ë¡œ ëŒ€ì²´
            - ìˆ˜ì •ëœ í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥ (ì„¤ëª… ì—†ì´)
            """
        }

        // Prewarm for better performance
        session?.prewarm()

        print("âœ… [STTFoundationModels] Foundation Models initialized")
    }

    /// Improve transcribed text with alternative candidates
    /// - Parameters:
    ///   - candidates: Multiple transcription candidates (first is primary)
    ///   - previousContext: Previous finalized text for better context (optional)
    /// - Returns: Improved text (best candidate selected and corrected)
    func improveTextWithAlternatives(candidates: [String], previousContext: String? = nil) async throws -> String {
        guard !candidates.isEmpty else { return "" }

        // í›„ë³´ê°€ í•˜ë‚˜ë¿ì´ë©´ ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
        if candidates.count == 1 {
            return try await improveText(candidates[0], previousContext: previousContext)
        }

        // Initialize session if needed
        if session == nil {
            try await initialize()
        }

        guard let session = session else {
            throw STTFoundationModelsError.sessionNotInitialized
        }

        print("ðŸ”„ [STTFoundationModels] Evaluating \(candidates.count) candidates")

        // Build prompt with alternatives
        let prompt = buildPromptWithAlternatives(candidates: candidates, context: previousContext)

        do {
            let options = GenerationOptions(temperature: configuration.temperature)
            let output = try await session.respond(to: prompt, options: options)
            let improvedText = output.content.trimmingCharacters(in: .whitespacesAndNewlines)

            print("âœ… [STTFoundationModels] Selected and improved: '\(improvedText)'")
            return improvedText

        } catch let error as LanguageModelSession.GenerationError {
            print("âŒ [STTFoundationModels] Generation error: \(error.localizedDescription)")
            return candidates[0]
        } catch {
            print("âŒ [STTFoundationModels] Error: \(error)")
            return candidates[0]
        }
    }

    /// Improve transcribed text with contextual corrections
    /// - Parameters:
    ///   - text: Original STT transcription text
    ///   - previousContext: Previous finalized text for better context (optional)
    /// - Returns: Improved text
    func improveText(_ text: String, previousContext: String? = nil) async throws -> String {
        guard !text.isEmpty else { return text }

        // Initialize session if needed
        if session == nil {
            try await initialize()
        }

        guard let session = session else {
            throw STTFoundationModelsError.sessionNotInitialized
        }

        print("ðŸ”„ [STTFoundationModels] Improving text: '\(text)'")
        if let previousContext = previousContext {
            print("ðŸ“– [STTFoundationModels] Context: '\(previousContext)'")
        }

        // Build prompt
        let prompt = buildPrompt(for: text, context: previousContext)
        print("ðŸ“ [STTFoundationModels] Prompt:\n\(prompt)\n")

        do {
            // Request text improvement with low temperature for consistency
            let options = GenerationOptions(temperature: configuration.temperature)
            let output = try await session.respond(to: prompt, options: options)
            let improvedText = output.content.trimmingCharacters(in: .whitespacesAndNewlines)

            print("âœ… [STTFoundationModels] Improved: '\(text)' â†’ '\(improvedText)'")
            return improvedText

        } catch let error as LanguageModelSession.GenerationError {
            print("âŒ [STTFoundationModels] Generation error: \(error.localizedDescription)")
            // Return original text if improvement fails
            return text
        } catch {
            print("âŒ [STTFoundationModels] Error improving text: \(error)")
            return text
        }
    }

    /// Improve text with streaming support (for real-time display)
    /// - Parameters:
    ///   - text: Original STT transcription text
    ///   - previousContext: Previous finalized text for better context (optional)
    /// - Returns: AsyncStream of improved text chunks
    func improveTextStreaming(_ text: String, previousContext: String? = nil) -> AsyncThrowingStream<String, Error> {
        AsyncThrowingStream { continuation in
            Task {
                do {
                    // Initialize session if needed
                    if session == nil {
                        try await initialize()
                    }

                    guard let session = session else {
                        throw STTFoundationModelsError.sessionNotInitialized
                    }

                    let prompt = buildPrompt(for: text, context: previousContext)

                    // Stream results
                    let stream = session.streamResponse(to: prompt)
                    for try await output in stream {
                        continuation.yield(output.content)
                    }

                    continuation.finish()

                } catch {
                    continuation.finish(throwing: error)
                }
            }
        }
    }

    // MARK: - Private Methods

    /// Build prompt for text improvement with alternative candidates
    private func buildPromptWithAlternatives(candidates: [String], context: String?) -> String {
        var prompt = ""

        if let context = context, !context.isEmpty {
            prompt += "[ì´ì „ ëŒ€í™”]\n\(context)\n\n"
        }

        prompt += "[ìŒì„±ì¸ì‹ í›„ë³´ë“¤]\n"
        for (index, candidate) in candidates.enumerated() {
            prompt += "\(index + 1). \(candidate)\n"
        }

        prompt += "\n[ìž‘ì—…]\n"
        prompt += "ìœ„ í›„ë³´ ì¤‘ ë§¥ë½ì— ê°€ìž¥ ë§žëŠ” ê²ƒì„ ì„ íƒí•˜ê³ , í•„ìš”ì‹œ ìµœì†Œí•œìœ¼ë¡œ ìˆ˜ì •í•˜ì„¸ìš”.\n"
        prompt += "ì—¬ëŸ¬ í›„ë³´ë¥¼ ì¡°í•©í•´ë„ ë©ë‹ˆë‹¤."

        return prompt
    }

    /// Build prompt for text improvement
    private func buildPrompt(for text: String, context: String?) -> String {
        var prompt = ""

        if let context = context, !context.isEmpty {
            prompt += "=== ì´ì „ ëŒ€í™” ë§¥ë½ (ì£¼ì œ íŒŒì•… í•„ìˆ˜) ===\n\(context)\n\n"
        } else {
            prompt += "=== ì´ì „ ëŒ€í™” ë§¥ë½ ===\n(ì—†ìŒ - ì²« ë¬¸ìž¥)\n\n"
        }

        prompt += "=== ìŒì„±ì¸ì‹ ê²°ê³¼ (ì˜¤ë¥˜ ìžˆìŒ) ===\n\(text)\n\n"
        prompt += "=== ìž‘ì—… ===\n"
        prompt += "1. ìœ„ ë§¥ë½ì—ì„œ ì£¼ì œê°€ ë¬´ì—‡ì¸ì§€ íŒŒì•…\n"
        prompt += "2. ìŒì„±ì¸ì‹ ê²°ê³¼ì—ì„œ ë§¥ë½ì— ë§žì§€ ì•ŠëŠ” ë‹¨ì–´ ì°¾ê¸°\n"
        prompt += "3. ìœ ì‚¬ ë°œìŒì˜ ì˜¬ë°”ë¥¸ ë‹¨ì–´ë¡œ êµì •\n"
        prompt += "4. ìˆ˜ì •ëœ í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥ (ì„¤ëª… ì—†ì´)\n\n"
        prompt += "ìˆ˜ì •ëœ í…ìŠ¤íŠ¸:"

        return prompt
    }

    /// Clean up resources
    func cleanup() {
        print("ðŸ›‘ [STTFoundationModels] Cleaning up...")
        session = nil
    }

    deinit {
        cleanup()
    }
}

// MARK: - Error Handling

@available(macOS 15.1, *)
enum STTFoundationModelsError: LocalizedError {
    case sessionNotInitialized
    case modelNotAvailable
    case textTooLong

    var errorDescription: String? {
        switch self {
        case .sessionNotInitialized:
            return "Foundation Models session is not initialized"
        case .modelNotAvailable:
            return "Foundation Models is not available on this device"
        case .textTooLong:
            return "Text is too long to process"
        }
    }
}

// MARK: - Convenience Extensions

@available(macOS 15.1, *)
extension STTFoundationModels {

    /// Batch improve multiple text segments
    func improveBatch(_ texts: [String], previousContext: String? = nil) async throws -> [String] {
        var results: [String] = []
        var context = previousContext

        for text in texts {
            let improved = try await improveText(text, previousContext: context)
            results.append(improved)

            // Update context for next iteration
            if let ctx = context {
                context = ctx + " " + improved
            } else {
                context = improved
            }
        }

        return results
    }

    /// Check if Foundation Models is available
    static func isAvailable() -> Bool {
        if #available(macOS 15.1, *) {
            return true
        }
        return false
    }
}
