//
//  AudioPipeline.swift
//  Openock
//
//  Created by YONGWON SEO on 11/5/25.
//

import Foundation
@preconcurrency import AVFoundation   // AVFAudio/AVFoundationì˜ Sendable ê²½ê³  ì–µì œ
@preconcurrency import AVFAudio
import Combine
import SwiftUI

@MainActor
final class AudioPipeline: ObservableObject {
  // MARK: - ê³µê°œ UI ìƒíƒœ
  @Published var yamStatus: String = "YAMNet: idle"
  @Published var transcript: String = ""
  @Published var isRecording: Bool = false
  @Published var isPaused: Bool = false

  // ë¼ìš°ë“œë‹ˆìŠ¤/ìŠ¤íƒ€ì¼
  @Published var loudnessDB: Double = 0
  @Published var fxStyle: SubtitleStyle = .neutral

  // (HEAD ì˜ë„) YAMNet í ì‹ í˜¸
  @Published var yamCue: YamCue?

  // (feat/#34 ì˜ë„) Whistle ë””ë²„ê·¸
  @Published var isWhistleDetected: Bool = false
  @Published var whistleProbability: Float = 0.0
  @Published var audioEnergy: Float = 0.0
  @Published var dominantFrequency: Float = 0.0
  @Published var stage1Probability: Float = 0.0
  @Published var stage2Probability: Float = 0.0

  // MARK: - ë‚´ë¶€ êµ¬ì„±ìš”ì†Œ
  private let capture = AudioCaptureManager()
  private let io = AudioIOManager()
  private let yamRunner = YAMNetRunner()
  private let loudness = LoudnessMeter()
  private let fxEngine = SubtitleFXEngine()

  @available(macOS 15.0, *)
  private let whistleDetector = WhistleDetector()
  @available(macOS 15.0, *)
  private let sttEngine = STTEngine()

  private var whistleManager: WhistleIndicatorWindowManager?

  // MARK: - Settings ìŠ¤ëƒ…ìƒ·
  private var settings: SettingsManager?
  private var currentFontSize: CGFloat = 24
  private var currentTextColor: Color = .black

  // MARK: - ê¸°ëŠ¥ í† ê¸€ (OnOffManagerê°€ ê°±ì‹ )
  private(set) var enableSizeFX: Bool = true
  private(set) var enableYamReactions: Bool = true
  private(set) var enableWhistle: Bool = true

  // MARK: - Combine
  private var bag = Set<AnyCancellable>()
  private var settingsBag = Set<AnyCancellable>()

  // MARK: - Resume Task ê´€ë¦¬
  private var resumeTask: Task<Void, Never>?

  // MARK: - Init
  init() {
    // YAM ìƒíƒœ í…ìŠ¤íŠ¸
    yamRunner.$statusText
      .receive(on: DispatchQueue.main)
      .assign(to: &$yamStatus)

    // (HEAD ì˜ë„) YAM cue ì‹ í˜¸ êµ¬ë…
    yamRunner.$cue
      .receive(on: DispatchQueue.main)
      .assign(to: &$yamCue)

    // STT ìë§‰
    if #available(macOS 15.0, *) {
      sttEngine.$transcript
        .receive(on: DispatchQueue.main)
        .assign(to: &$transcript)
    }

    whistleManager = WhistleIndicatorWindowManager(pipeline: self)

    // MARK: dB â†’ FX ê°±ì‹  (í† ê¸€ + í•˜ì´ë¼ì´íŠ¸ ìƒ‰ ë°˜ì˜)
    loudness.$dB
      .receive(on: DispatchQueue.main)
      .sink { [weak self] db in
        guard let self else { return }
        self.loudnessDB = db

        if self.enableSizeFX {
          // SettingsManagerì—ì„œ ì„ íƒí•œ ê°•ì¡°ìƒ‰ ì‚¬ìš© (ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ ìƒ‰ìœ¼ë¡œ fallback)
          let highlight = self.settings?.highlightColor ?? self.currentTextColor

          self.fxEngine.update(
            dB: db,
            baseFontSize: self.currentFontSize,
            baseTextColor: self.currentTextColor,
            highlightColor: highlight
          )
        } else {
          self.fxStyle = .neutral
        }
      }
      .store(in: &bag)

    // fxEngine â†’ fxStyle (í† ê¸€ ë°©ì–´)
    fxEngine.$style
      .receive(on: DispatchQueue.main)
      .sink { [weak self] style in
        guard let self else { return }
        self.fxStyle = self.enableSizeFX ? style : .neutral
      }
      .store(in: &bag)
  }

  // MARK: - Settings ë°”ì¸ë”©
  func bindSettings(_ settings: SettingsManager) {
    self.settings = settings
    settingsBag.removeAll()

    // ì´ˆê¸° ìŠ¤ëƒ…ìƒ·
    currentFontSize = settings.fontSize
    currentTextColor = settings.textColor

    // ê¸€ê¼´ í¬ê¸° ë³€ê²½ â†’ ìƒëŒ€ í™•ëŒ€ ì¬ê³„ì‚°
    settings.$fontSize
      .receive(on: DispatchQueue.main)
      .sink { [weak self] size in
        guard let self else { return }
        self.currentFontSize = size
        self.refreshFXStyle()
      }
      .store(in: &settingsBag)

    // ë°°ê²½ í”„ë¦¬ì…‹ ë³€ê²½ â†’ í…ìŠ¤íŠ¸ ìƒ‰ ì¬ìŠ¤ëƒ…ìƒ·
    settings.$selectedBackground
      .receive(on: DispatchQueue.main)
      .sink { [weak self, weak settings] _ in
        guard let self, let settings else { return }
        self.currentTextColor = settings.textColor
        self.refreshFXStyle()
      }
      .store(in: &settingsBag)

    // ì»¤ìŠ¤í…€ ì»¬ëŸ¬ ì €ì¥(ìƒ‰ìƒ í”¼ì»¤ ë“±) â†’ í…ìŠ¤íŠ¸ ìƒ‰ ì¬ìŠ¤ëƒ…ìƒ·
    NotificationCenter.default.publisher(for: UserDefaults.didChangeNotification)
      .debounce(for: .milliseconds(250), scheduler: DispatchQueue.main)
      .sink { [weak self, weak settings] _ in
        guard let self, let settings else { return }
        self.currentTextColor = settings.textColor
        self.refreshFXStyle()
      }
      .store(in: &settingsBag)

    refreshFXStyle()
  }

  // MARK: - FX Style ì¬ê³„ì‚°
  private func refreshFXStyle() {
    guard enableSizeFX else {
      fxStyle = .neutral
      return
    }
    let highlight = settings?.highlightColor ?? currentTextColor

    fxEngine.update(
      dB: loudnessDB,
      baseFontSize: currentFontSize,
      baseTextColor: currentTextColor,
      highlightColor: highlight
    )
  }

  // MARK: - ìº¡ì²˜ + IO
  func setupAndStart() {
    // ì´ë¯¸ ë…¹ìŒ ì¤‘ì´ë©´ ë¬´ì‹œ
    if isRecording {
      print("â„¹ï¸ [AudioPipeline] setupAndStart() called while already recording â€“ ignored")
      return
    }

    DispatchQueue.main.async { [weak self] in
      guard let self = self else { return }
      self.isRecording = true
      self.isPaused = false
    }

    capture.setupFullSystemCapture { [weak self] deviceID in
      guard let self = self else { return }
      guard let devID = deviceID else {
        print("âŒ [AudioPipeline] setupFullSystemCapture failed")
        self.isRecording = false
        self.isPaused = false
        return
      }

      print("ğŸ§ [AudioPipeline] Using aggregate deviceID: \(devID)")

      // ğŸ‘‰ STT ë¨¼ì € ì„¸íŒ…í•˜ê³ , ëë‚œ ë’¤ì— IO ì‹œì‘
      if #available(macOS 15.0, *) {
        Task { @MainActor in
          print("ğŸ™ï¸ [AudioPipeline] Starting STT transcription-only pipeline...")
          await self.sttEngine.startTranscriptionOnly()

          // STT ìª½ì—ì„œ íŠ¸ëœìŠ¤í¬ë¼ì´ë²„/ì• ë„ë¼ì´ì € ì´ˆê¸°í™”í•  ì‹œê°„ ì¡°ê¸ˆ ì¤Œ
          // (ì˜ˆì „ STTEngineì—ì„œë„ 0.1ì´ˆ ìŠ¬ë¦½ ì“°ë˜ íŒ¨í„´ ê·¸ëŒ€ë¡œ ì—°ì¥)
          try? await Task.sleep(nanoseconds: 300_000_000) // 0.3ì´ˆ

          self.startIOWithDevice(devID)
        }
      } else {
        // macOS 15 ë¯¸ë§Œì´ë©´ STT ì—†ì´ ë°”ë¡œ IO
        self.startIOWithDevice(devID)
      }
    }
  }

  // IO ì‹œì‘ ë¶€ë¶„ë§Œ í•¨ìˆ˜ë¡œ ëºŒ (ì¤‘ë³µ ì¤„ì´ë ¤ê³ )
  private func startIOWithDevice(_ devID: AudioObjectID) {
    let ok = self.io.startIO(
      deviceID: devID,
      bufferCallback: { [weak self] pcm in
        guard let self else { return }

        // STT: í•­ìƒ ë™ì‘
        if #available(macOS 15.0, *) {
          self.sttEngine.feed(buffer: pcm)
        }

        // YAM ë°˜ì‘
        if self.enableYamReactions {
          self.yamRunner.ingest(pcm)
        }

        // Whistle (ì§€ê¸ˆì€ ì ê¹ êº¼ë‘ëŠ” ê±¸ ì¶”ì²œ)
        if self.enableWhistle, #available(macOS 15.0, *) {
          self.handleWhistleDetection(buffer: pcm)
        }

        // ë¼ìš°ë“œë‹ˆìŠ¤
        self.loudness.ingest(pcm)
      },
      levelCallback: { _ in }
    )

    self.isRecording = ok
    self.isPaused = false

    if !ok {
      print("âŒ [AudioPipeline] io.startIO failed")
    } else if !self.enableYamReactions {
      self.yamStatus = "YAMNet: disabled"
    }
  }

  // MARK: - Public controls
  func startRecording() { setupAndStart() }

  func stop() {
    io.stopIO()
    capture.cleanup()
    if #available(macOS 15.0, *) {
      sttEngine.stopTranscriptionOnly()
    }
    isRecording = false
    isPaused = false
  }

  func pauseRecording() {
    print("â¸ [AudioPipeline] Pausing recording...")

    // ì§„í–‰ ì¤‘ì¸ resume task ì·¨ì†Œ
    if resumeTask != nil {
      print("ğŸ”´ [AudioPipeline] Cancelling active resume task")
      resumeTask?.cancel()
      resumeTask = nil
    }

    io.isPaused = true
    isPaused = true
    print("âœ… [AudioPipeline] Paused - io.isPaused: \(io.isPaused), isPaused: \(isPaused)")
  }

  func resumeRecording() {
    print("â–¶ï¸ [AudioPipeline] Resuming recording...")
    print("ğŸ“Š [AudioPipeline] Current state - io.isPaused: \(io.isPaused), isPaused: \(isPaused)")

    // ì¬ìƒ ë²„íŠ¼ ëˆ„ë¥¼ ë•Œ ì˜¤ë””ì˜¤ íƒ­ ê°±ì‹  (ìƒˆë¡œìš´ ì˜¤ë””ì˜¤ í”„ë¡œì„¸ìŠ¤ ê°ì§€)
    DispatchQueue.global(qos: .userInitiated).async { [weak self] in
      self?.capture.refreshAudioTap()
    }

    // ì´ì „ resume task ì·¨ì†Œ
    resumeTask?.cancel()

    if #available(macOS 15.0, *) {
      // STT ì¬ì‹œì‘ ì¤‘ì—ëŠ” ì¼ì‹œì ìœ¼ë¡œ pause ìƒíƒœ ìœ ì§€ (ë²„í¼ ë¬´ì‹œ)
      io.isPaused = true
      isPaused = true

      // STT ì¬ì‹œì‘ì„ ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬
      resumeTask = Task { @MainActor in
        print("ğŸ”„ [AudioPipeline] Task started - stopping STT...")

        // STT ì¤‘ì§€ ë° ì´ˆê¸°í™”
        self.sttEngine.stopTranscriptionOnly()
        self.sttEngine.clearTranscript()
        self.transcript = ""

        print("ğŸ”„ [AudioPipeline] Starting STT...")
        await self.sttEngine.startTranscriptionOnly()

        // Taskê°€ ì·¨ì†Œë˜ì—ˆëŠ”ì§€ í™•ì¸
        if Task.isCancelled {
          print("âš ï¸ [AudioPipeline] Resume task was cancelled after STT start")
          return
        }

        // Additional delay to ensure analyzers are fully ready
        print("â³ [AudioPipeline] Waiting for analyzers to fully initialize...")
        try? await Task.sleep(nanoseconds: 300_000_000) // 0.3 seconds

        // Taskê°€ ì·¨ì†Œë˜ì—ˆëŠ”ì§€ ë‹¤ì‹œ í™•ì¸
        if Task.isCancelled {
          print("âš ï¸ [AudioPipeline] Resume task was cancelled during sleep")
          return
        }

        print("âœ… [AudioPipeline] STT ready, unpausing IO...")
        // STTê°€ ì¤€ë¹„ëœ í›„ì— ì˜¤ë””ì˜¤ ì¬ê°œ
        self.io.isPaused = false
        self.isPaused = false
        print("âœ… [AudioPipeline] Resumed - io.isPaused: \(self.io.isPaused), isPaused: \(self.isPaused)")
      }
    } else {
      // macOS 15.0 ë¯¸ë§Œì—ì„œëŠ” STT ì—†ì´ ë°”ë¡œ ì¬ê°œ
      io.isPaused = false
      isPaused = false
      transcript = ""
    }
  }

  // MARK: - Whistle (Sendable ê²½ê³  íšŒí”¼: ë”¥ì¹´í”¼ í›„ ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬)
  @available(macOS 15.0, *)
  private func handleWhistleDetection(buffer: AVAudioPCMBuffer) {
    guard let copied = Self.deepCopyPCMBuffer(buffer) else { return }

    DispatchQueue.global(qos: .userInitiated).async { [weak self] in
      guard let self = self else { return }
      let detected = self.whistleDetector.detectWhistle(from: copied)

      DispatchQueue.main.async {
        self.whistleProbability = self.whistleDetector.lastWhistleProbability
        self.audioEnergy = self.whistleDetector.lastRMSEnergy
        self.dominantFrequency = self.whistleDetector.lastDominantFrequency
        self.stage1Probability = self.whistleDetector.lastStage1Probability
        self.stage2Probability = self.whistleDetector.lastStage2Probability
      }

      if detected {
        DispatchQueue.main.async { self.isWhistleDetected = true }
        DispatchQueue.main.asyncAfter(deadline: .now() + 3.0) {
          self.isWhistleDetected = false
        }
      }
    }
  }

  // MARK: - AVAudioPCMBuffer ì•ˆì „ ë³µì œ
  private static func deepCopyPCMBuffer(_ src: AVAudioPCMBuffer) -> AVAudioPCMBuffer? {
    let format = src.format
    guard let dst = AVAudioPCMBuffer(pcmFormat: format, frameCapacity: src.frameCapacity) else { return nil }
    dst.frameLength = src.frameLength

    let frames = Int(src.frameLength)
    let channels = Int(format.channelCount)

    switch format.commonFormat {
    case .pcmFormatFloat32:
      guard let s = src.floatChannelData, let d = dst.floatChannelData else { return nil }
      let bytes = frames * MemoryLayout<Float>.size
      for ch in 0..<channels { memcpy(d[ch], s[ch], bytes) }
    case .pcmFormatInt16:
      guard let s = src.int16ChannelData, let d = dst.int16ChannelData else { return nil }
      let bytes = frames * MemoryLayout<Int16>.size
      for ch in 0..<channels { memcpy(d[ch], s[ch], bytes) }
    case .pcmFormatInt32:
      guard let s = src.int32ChannelData, let d = dst.int32ChannelData else { return nil }
      let bytes = frames * MemoryLayout<Int32>.size
      for ch in 0..<channels { memcpy(d[ch], s[ch], bytes) }
    default:
      let srcList = unsafeBitCast(src.audioBufferList, to: UnsafeMutablePointer<AudioBufferList>.self)
      let sABL = UnsafeMutableAudioBufferListPointer(srcList)
      let dABL = UnsafeMutableAudioBufferListPointer(dst.mutableAudioBufferList)
      for i in 0..<sABL.count {
        let byteSize = Int(sABL[i].mDataByteSize)
        if byteSize > 0, let sp = sABL[i].mData, let dp = dABL[i].mData {
          memcpy(dp, sp, byteSize)
          dABL[i].mDataByteSize = sABL[i].mDataByteSize
        }
      }
    }
    return dst
  }

  // MARK: - On/Off ì ìš©(API)
  func applySizeFXEnabled(_ on: Bool) {
    enableSizeFX = on
    if !on {
      fxStyle = .neutral
    } else {
      refreshFXStyle()
    }
  }

  func applyYamReactionsEnabled(_ on: Bool) {
    enableYamReactions = on
    yamStatus = on ? "YAMNet: idle" : "YAMNet: disabled"
  }

  func applyWhistleEnabled(_ on: Bool) {
    enableWhistle = on
    if !on {
      isWhistleDetected = false
      whistleProbability = 0
      stage1Probability = 0
      stage2Probability = 0
    }
  }
}
