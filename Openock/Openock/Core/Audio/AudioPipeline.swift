//
//  AudioPipeline.swift
//  Openock
//
//  Created by YONGWON SEO on 11/5/25.
//

import Foundation
import AVFoundation
import Combine

final class AudioPipeline: ObservableObject {
    // UI ìƒíƒœ
    @Published var yamStatus: String = "YAMNet: idle"
    @Published var transcript: String = ""
    @Published var isRecording: Bool = false
    @Published var isPaused: Bool = false

    // í˜¸ë£¨ë¼ê¸° ê°ì§€ ìƒíƒœ
    @Published var isWhistleDetected: Bool = false
    @Published var whistleProbability: Float = 0.0
    @Published var audioEnergy: Float = 0.0
    @Published var dominantFrequency: Float = 0.0
    @Published var stage1Probability: Float = 0.0
    @Published var stage2Probability: Float = 0.0

    // ë‚´ë¶€ êµ¬ì„±ìš”ì†Œ
    private let capture = AudioCaptureManager()
    private let io = AudioIOManager()
    private let yamRunner = YAMNetRunner()

    // í˜¸ë£¨ë¼ê¸° ê°ì§€ê¸°
    @available(macOS 15.0, *)
    private let whistleDetector = WhistleDetector()

    // âœ… íŒ€ ê³µìš© STT ì—”ì§„ ì‚¬ìš© (ë¶„ì„ íŒŒì´í”„ë¼ì¸ë§Œ ì‚¬ìš©)
    @available(macOS 15.0, *)
    private let sttEngine = STTEngine()

    private var bag = Set<AnyCancellable>()
    private var bufferCallCount = 0

    init() {
        // YAM ìƒíƒœ ë°˜ì˜
        yamRunner.$statusText
            .receive(on: DispatchQueue.main)
            .assign(to: &$yamStatus)

        // âœ… STTEngineì˜ transcript ë°˜ì˜
        if #available(macOS 15.0, *) {
            sttEngine.$transcript
                .receive(on: DispatchQueue.main)
                .assign(to: &$transcript)
        }
    }

    // ìº¡ì²˜ + IO ì‹œì‘
    func setupAndStart() {
        capture.setupFullSystemCapture { [weak self] deviceID in
            guard let self, let devID = deviceID else { return }

            // âœ… STTEngine: ìº¡ì²˜/IOëŠ” ì“°ì§€ ì•Šê³ , ë¶„ì„ íŒŒì´í”„ë¼ì¸ë§Œ ì¼œê¸°
            if #available(macOS 15.0, *) {
                Task { @MainActor in
                    await self.sttEngine.startTranscriptionOnly()
                }
            }

            let ok = self.io.startIO(
                deviceID: devID,
                bufferCallback: { [weak self] pcm in
                    guard let self else { return }
                    // 1) YAMNet (ëŸ¬ë„ˆê°€ ë‚´ë¶€ì—ì„œ 16k ë³€í™˜)
                    self.yamRunner.ingest(pcm)
                    // 2) STT (ì›ë³¸ PCM ê·¸ëŒ€ë¡œ ì „ë‹¬)
                    if #available(macOS 15.0, *) {
                        self.sttEngine.feed(buffer: pcm)
                        // 3) í˜¸ë£¨ë¼ê¸° ê°ì§€
                        self.handleWhistleDetection(buffer: pcm)
                    }
                },
                levelCallback: { _ in }
            )

            DispatchQueue.main.async {
                self.isRecording = ok
                self.isPaused = false
            }
        }
    }

    func startRecording() { // ë·°ì—ì„œ í˜¸ì¶œ
        setupAndStart()
    }

    func stop() {
        io.stopIO()
        capture.cleanup()
        if #available(macOS 15.0, *) {
            sttEngine.stopTranscriptionOnly()   // âœ… ì „ì‚¬ íŒŒì´í”„ë¼ì¸ë§Œ ì •ë¦¬
        }
        isRecording = false
        isPaused = false
    }

    func pauseRecording() {
        io.isPaused = true
        isPaused = true
    }

    func resumeRecording() {
        io.isPaused = false
        isPaused = false
    }

    // MARK: - í˜¸ë£¨ë¼ê¸° ê°ì§€
    @available(macOS 15.0, *)
    private func handleWhistleDetection(buffer: AVAudioPCMBuffer) {
        bufferCallCount += 1

        // ë§¤ ë²„í¼ë§ˆë‹¤ ì²´í¬í•˜ì—¬ ëª¨ë“  ì†Œë¦¬ ì…ë ¥ì— ëŒ€í•´ ì‹¤ì‹œê°„ ê°’ í‘œì‹œ
        if bufferCallCount % 1 == 0 {
            // ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰í•˜ì—¬ ë©”ì¸ ì˜¤ë””ì˜¤ ì²˜ë¦¬ì— ì˜í–¥ ì—†ë„ë¡
            DispatchQueue.global(qos: .userInitiated).async { [weak self] in
                guard let self = self else { return }
                let whistleDetected = self.whistleDetector.detectWhistle(from: buffer)

                // UIì— ë””ë²„ê¹… ì •ë³´ ì—…ë°ì´íŠ¸ (ëª¨ë“  ì†Œë¦¬ ì…ë ¥ì— ëŒ€í•´)
                DispatchQueue.main.async {
                    self.whistleProbability = self.whistleDetector.lastWhistleProbability
                    self.audioEnergy = self.whistleDetector.lastRMSEnergy
                    self.dominantFrequency = self.whistleDetector.lastDominantFrequency
                    self.stage1Probability = self.whistleDetector.lastStage1Probability
                    self.stage2Probability = self.whistleDetector.lastStage2Probability
                }

                if whistleDetected {
                    DispatchQueue.main.async {
                        self.isWhistleDetected = true
                        print("ğŸµ [AudioPipeline] Whistle detected!")
                    }

                    // 3ì´ˆ í›„ ìë™ìœ¼ë¡œ ì•„ì´ì½˜ ì‚¬ë¼ì§€ê²Œ
                    DispatchQueue.main.asyncAfter(deadline: .now() + 3.0) {
                        self.isWhistleDetected = false
                    }
                }
            }
        }
    }
}
